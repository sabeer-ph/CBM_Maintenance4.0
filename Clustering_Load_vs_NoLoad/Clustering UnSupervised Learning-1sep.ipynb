{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing modules needed\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import openpyxl\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy.fftpack import irfft, rfft\n",
    "\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder path created for code and also the raw files\n",
    "p1 = os.getcwd()\n",
    "p2 = 'Final_Raw_Data'\n",
    "path = os.path.join(p1,p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('299cfe16.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Data_pull_time', 'Mac_Id', 'Axis', 'Vsample1', 'Vsample2', 'Vsample3',\n",
       "       'Vsample4', 'Vsample5', 'Vsample6', 'Vsample7',\n",
       "       ...\n",
       "       'Vsample4087', 'Vsample4088', 'Vsample4089', 'Vsample4090',\n",
       "       'Vsample4091', 'Vsample4092', 'Vsample4093', 'Vsample4094',\n",
       "       'Vsample4095', 'Vsample4096'],\n",
       "      dtype='object', length=4099)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = pd.DataFrame()\n",
    "processed = df[['Data_pull_time', 'Mac_Id', 'Axis']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_pull_time</th>\n",
       "      <th>Mac_Id</th>\n",
       "      <th>Axis</th>\n",
       "      <th>RMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-08-31 08:34:36</td>\n",
       "      <td>29:9c:fe:16</td>\n",
       "      <td>X</td>\n",
       "      <td>17.398653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-08-31 09:07:45</td>\n",
       "      <td>29:9c:fe:16</td>\n",
       "      <td>X</td>\n",
       "      <td>17.105179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-08-31 09:32:04</td>\n",
       "      <td>29:9c:fe:16</td>\n",
       "      <td>X</td>\n",
       "      <td>19.647579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-08-31 11:07:56</td>\n",
       "      <td>29:9c:fe:16</td>\n",
       "      <td>X</td>\n",
       "      <td>23.202746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-08-31 11:48:18</td>\n",
       "      <td>29:9c:fe:16</td>\n",
       "      <td>X</td>\n",
       "      <td>21.528653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Data_pull_time       Mac_Id Axis        RMS\n",
       "0 2020-08-31 08:34:36  29:9c:fe:16    X  17.398653\n",
       "1 2020-08-31 09:07:45  29:9c:fe:16    X  17.105179\n",
       "2 2020-08-31 09:32:04  29:9c:fe:16    X  19.647579\n",
       "3 2020-08-31 11:07:56  29:9c:fe:16    X  23.202746\n",
       "4 2020-08-31 11:48:18  29:9c:fe:16    X  21.528653"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\husssabe\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "processed['RMS'] =  (df.loc[:,'Vsample1':'Vsample4096']**2).sum(1).pow(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_final.Defect_Introduced.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_final.set_index(\"index\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_final.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Data = Data_final.copy()\n",
    "#processed = Data.loc[:,'Data_pull_time':'Sensor_Loc']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "processed['Max'] = Data.loc[:,'Vsample1':'Vsample4096'].max(axis=1)\n",
    "processed['Min'] = Data.loc[:,'Vsample1':'Vsample4096'].min(axis=1)\n",
    "processed['Mean'] = Data.loc[:,'Vsample1':'Vsample4096'].mean(axis=1)\n",
    "processed['Std'] = Data.loc[:,'Vsample1':'Vsample4096'].std(axis=1)\n",
    "processed['P2P'] = Data.loc[:,'Vsample1':'Vsample4096'].max(axis=1) - Data.loc[:,'Vsample1':'Vsample4096'].min(axis=1)\n",
    "processed['Kurt'] = Data.loc[:,'Vsample1':'Vsample4096'].kurt(axis=1)\n",
    "processed['RMS'] =  (Data.loc[:,'Vsample1':'Vsample4096']**2).sum(1).pow(1/2)\n",
    "processed['Var'] = Data.loc[:,'Vsample1':'Vsample4096'].var(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed.head()\n",
    "#processed.Defect_Introduced.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adding frequency bins to processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Processed = pd.DataFrame()\n",
    "sec = 1.2792877225866917\n",
    "N = 4096\n",
    "fs_rate=round(N/sec)\n",
    "fs_rate\n",
    "Ts = 1.0/fs_rate # sampling interval in time\n",
    "t = np.arange(0, secs, Ts) # time vector as scipy arange field / numpy.ndarray\n",
    "freqs = scipy.fftpack.fftfreq(N, t[1]-t[0])\n",
    "print(len(freqs))\n",
    "freqs_side = freqs[range(N//2)] # one side frequency range\n",
    "print(len(freqs_side))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Processed = pd.DataFrame()\n",
    "sec = 1.2792877225866917\n",
    "N = 4096\n",
    "fs_rate=round(N/sec)\n",
    "fs_rate\n",
    "Ts = 1.0/fs_rate # sampling interval in time\n",
    "t = np.arange(0, secs, Ts) # time vector as scipy arange field / numpy.ndarray\n",
    "freqs = scipy.fftpack.fftfreq(N, t[1]-t[0])\n",
    "freqs_side = freqs[range(N//2)] # one side frequency range\n",
    "## high pass filter\n",
    "for i,row in Data.iterrows():\n",
    "    data = row['Vsample1':'Vsample4096'] - row['Vsample1':'Vsample4096'].mean() # subracting mean from the samples\n",
    "    #print(row[\"Data_pull_time\":\"Sensor_Loc\"])\n",
    "    f_signal = rfft(data)\n",
    "    #print(row['Vsample1':'Vsample6'])\n",
    "    #print(f_signal[:5])\n",
    "    #print(len(f_signal))\n",
    "    #If our original signal time was in seconds, this is now in Hz    \n",
    "    cut_f_signal = f_signal.copy()\n",
    "    #cut_f_signal[(freqs<6) & (freqs>-6)] = 0\n",
    "    data = irfft(cut_f_signal)\n",
    "    rms = np.sqrt(np.mean(np.array(data)**2))\n",
    "    kurt=stats.kurtosis(data)\n",
    "    if rms>.02 and kurt<300 and freqs_side[-1]>1550: ## to keep the range at least 800 hz\n",
    "        FFT = scipy.fft.fft(data)\n",
    "        FFT_side = FFT[range(N//2)] # one side FFT range, because we need just the haf of the frequency data because of symmetry\n",
    "        abs_fft_1=abs(FFT_side)\n",
    "        \n",
    "        payload={\n",
    "                        \"Data_pull_time\" : row[\"Data_pull_time\"],\n",
    "                        \"Mac_Id\" : row[\"Mac_Id\"],\n",
    "                        \"Axis\" : row[\"Axis\"],\n",
    "                        \"Defect_Introduced\" : row[\"Defect_Introduced\"],\n",
    "                        \"Asset_Id\" : row[\"Asset_Id\"],\n",
    "                        \"Sensor_Loc\":row[\"Sensor_Loc\"],\n",
    "                        \"peak-peak\": (max(data)-min(data)),\n",
    "                        \"rms\": rms,\n",
    "                        \"kurt\":kurt,\n",
    "                        \"crest\":np.max(np.abs(data))/np.sqrt(np.mean(np.square(data))),\n",
    "                        \"variance\":np.var(data),\n",
    "                        \"mean\":np.mean(data),\n",
    "                        \"skewness\":stats.skew(data),\n",
    "                        'freqAmpliMean':np.mean(abs_fft_1),\n",
    "                        'freqAmpliMax':max(abs_fft_1),\n",
    "                        'freqAmpliKurt':stats.kurtosis(abs_fft_1),\n",
    "                        'freqAmpliskw':stats.skew(abs_fft_1),\n",
    "                        'freqAmpliVar':np.var(abs_fft_1),\n",
    "                        }\n",
    "        lenFreq=len(freqs_side)\n",
    "        lastFreq=freqs_side[-1]\n",
    "        abs_fft_1=list(abs_fft_1)\n",
    "        jj=0\n",
    "        feqv=1\n",
    "        while jj < lenFreq and feqv<=8: ## for 8 bins from 0 to 1600 Hz\n",
    "            #print('Condition satisfied')\n",
    "            kk=int(round(jj+lenFreq/lastFreq*200)) ## 100 is freqency step size for binnning\n",
    "            #print(kk)\n",
    "            fft_Range=abs_fft_1[jj:kk]\n",
    "            freq_sideRange=freqs_side[jj:kk]\n",
    "            jj=kk\n",
    "            payload['max_{}'.format(feqv)]=max(fft_Range)\n",
    "            payload['mean_{}'.format(feqv)]=np.mean(fft_Range)\n",
    "            payload['var_{}'.format(feqv)]=np.var(fft_Range)\n",
    "            feqv+=1\n",
    "        Data_Processed = Data_Processed.append(payload, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "#for i,row in Data.iterrows():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        lenFreq=len(freqs_side)\n",
    "        lastFreq=freqs_side[-1]\n",
    "        abs_fft_1=list(abs_fft_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenFreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = Data.iloc[0][\"Vsample1\":\"Vsample4096\" ]\n",
    "raw_mean = Data.iloc[0][\"Vsample1\":\"Vsample4096\" ] - Data.iloc[0][\"Vsample1\":\"Vsample4096\" ].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Processed.to_excel('Processed-sample.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.skew(raw_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(raw_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### convert raw data to FFT\n",
    "\n",
    "FFT = scipy.fft.fft(raw_mean)\n",
    "plt.plot(abs(FFT[range(75,N//2)]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = scipy.fftpack.fftfreq(N, t[1]-t[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(abs(FFT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_data.to_excel('FFT_Data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_data['Raw_data'] = raw_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_data['FFT'] = FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_data['abs_data'] = abs(FFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_signal = rfft(raw_mean)\n",
    "fft_data['Rfft'] = f_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(f_signal)\n",
    "#len((freqs<6) & (freqs>-6))\n",
    "f_signal[(freqs<6) & (freqs>-6)]\n",
    "f_signal.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_signal[(freqs<6) & (freqs>-6)] = 0\n",
    "fft_data['Rfft_6Freq'] = f_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_signal.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.loc[0:0,'Vsample1':'Vsample4096']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = Data_final.iloc[228]['Vsample1':'Vsample4096']\n",
    "N=4096\n",
    "sec = 1.279374957\n",
    "fs_rate=round(N/sec) ## alternatively that means frequency\n",
    "\n",
    "   \n",
    "secs = N / float(fs_rate) ## time for which it will be played in sec\n",
    "\n",
    "Ts = 1.0/fs_rate # sampling interval in time\n",
    "\n",
    "t = np.arange(0, secs, Ts) # time vector as scipy arange field / numpy.ndarray\n",
    "\n",
    "freqs = scipy.fft.fftfreq(N, t[1]-t[0])\n",
    "print(freqs[4095])\n",
    "freqs_side = freqs[range(N//2)] # one side frequency range\n",
    "               \n",
    "                ## caliberate the sensor in case there is gravitational effect left from the sensor settings\n",
    "data = Data.iloc[4]['Vsample1':'Vsample4096']\n",
    "meanVal=np.mean(data)\n",
    "data-=meanVal\n",
    "   \n",
    "FFT = scipy.fft.fft(raw_mean)\n",
    "FFT_side = FFT[range(N//2)] # one side FFT range, because we need just the haf of the frequency data because of symmetry\n",
    "abs_fft_1=2*abs(FFT_side)/N\n",
    "\n",
    "\n",
    "type(abs_fft_1)\n",
    "#plt.plot(abs(FFT[range(N//2)]))\n",
    "plt.plot(FFT)\n",
    "\n",
    "1/t[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "model = KMeans(n_clusters=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(processed[[\"P2P\",\"RMS\",\"Mean\",\"Max\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = model.predict(processed[[\"P2P\",\"RMS\",\"Mean\",\"Max\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### understanding our cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"red\", \"orange\", \"green\", \"blue\", \"purple\", \"gray\"]\n",
    "Fault = [\"Hanoi\", \"Nha Trang\", \"Vung Tau\", \"Phu Quoc\", \"Quang Ngai\", \"Saigon\"]\n",
    "region_colors=dict(zip(regions,colors))\n",
    "\n",
    "grp_color=[]\n",
    "for i in data['Region']:\n",
    "    grp_color.append(region_colors[i]) \n",
    "\n",
    "x_long=data[' Longitude']\n",
    "y_lat=data[\" Latitude\"]\n",
    "plt.scatter(x_long,y_lat,c=grp_color)\n",
    "plt.legend(grp_color,regions,loc='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.scatter(processed.P2P,processed.RMS, c=processed[\"Actual_Cluster\"].apply(lambda x: colors[x]),label=)\n",
    "plt.show()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = model.cluster_centers_\n",
    "centroids_x = centroids[:,0]\n",
    "centroids_y = centroids[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(processed.P2P,processed.RMS, c=labels)\n",
    "plt.scatter(centroids_x, centroids_y, marker='X', s=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Load_NoLoad_group = {\"No Defect_No Load\": \"No_Load\",\n",
    "                     \"No Defect_Empty Tray\":\"Load\",\n",
    "                     \"No Defect_with no tray\" : \"No_Load\" }\n",
    "\n",
    "processed[\"Actual_Cluster\"] = [ Load_NoLoad_group[i] for i in processed.Defect_Introduced]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed[\"Cluster\"] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed[[\"Defect_Introduced\",\"Actual_Cluster\",\"Cluster\"]].to_excel(\"Cluster_data_2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(processed.P2P,processed.RMS, c=processed[\"Cluster\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "    ax.scatter(x, y, c=color, s=scale, label=color,\n",
    "               alpha=0.3, edgecolors='none')\n",
    "\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#row = Data_final.iloc[228]['Vsample1':'Vsample4096']\n",
    "N=4096\n",
    "sec = 1.279374957\n",
    "fs_rate=round(N/sec) ## alternatively that means frequency\n",
    "\n",
    "   \n",
    "secs = N / float(fs_rate) ## time for which it will be played in sec\n",
    "\n",
    "Ts = 1.0/fs_rate # sampling interval in time\n",
    "\n",
    "t = np.arange(0, secs, Ts) # time vector as scipy arange field / numpy.ndarray\n",
    "\n",
    "freqs = scipy.fft.fftfreq(N, t[1]-t[0])\n",
    "#print(freqs[4095])\n",
    "freqs_side = freqs[range(N//2)] # one side frequency range\n",
    "\n",
    "for j in ['X','Y','Z']:\n",
    "    print(j)\n",
    "    for i,row in Data_final[(Data_final.Defect_Introduced == \"No Defect_Empty Tray\")  & (Data_final.Asset_Id == \"101.CA.DTL.01.1-030\") & (Data_final.Axis == j)].head().iterrows():\n",
    "    #if (row['Vsample1':'Vsample4096'].max() > 2) and (row['Vsample1':'Vsample4096'].min() < 0) :\n",
    "        data = row['Vsample1':'Vsample4096']\n",
    "        fig, axs = plt.subplots(2)\n",
    "        axs[0].plot(data)\n",
    "        axs[0].set_ylim(-4,4)\n",
    "        fig.suptitle(str(row['Data_pull_time']) +'\\n'+row['Defect_Introduced']+'\\n'+row['Sensor_Loc'])\n",
    "        #fig.title(str(row['Data_pull_time'])+' '+row['Axis'])\n",
    "        \n",
    "        FFT = scipy.fft.fft(data)\n",
    "        axs[1].plot(FFT)\n",
    "        fig.savefig('./101.CA.DTL.01.1-030/Load/'+j+'/'+row['Mac_Id'].replace(\":\",\"\")+'_'+row['Axis']+'_'+str(i)+'.png',dpi=400)\n",
    "        #fig.savefig('test.png')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in ['X','Y','Z']:\n",
    "    for i,row in Data_final[(Data_final.Defect_Introduced == \"No Defect_No Load\")  & (Data_final.Asset_Id == \"101.CA.DTL.01.1-050\") & (Data_final.Axis == j)].iterrows():\n",
    "        #if (row['Vsample1':'Vsample4096'].max() > 2) and (row['Vsample1':'Vsample4096'].min() < 0) :\n",
    "        plot = row['Vsample1':'Vsample4096'].plot()\n",
    "        plot.set_ylim(-4,4)\n",
    "        fig = plot.get_figure()\n",
    "        plt.suptitle(str(row['Data_pull_time'])+' '+row['Axis'])\n",
    "        plt.title(row['Defect_Introduced']+' '+row['Sensor_Loc'])\n",
    "        fig.savefig('./101.CA.DTL.01.1-030/Load/X/'+row['Mac_Id'].replace(\":\",\"\")+'_'+row['Axis']+'_'+str(i)+'.png')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, \n",
    "           sharex='col', sharey='row')\n",
    "\n",
    "ax[0].plot(row)\n",
    "\n",
    "ax[1].plot([3,4,5])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = Data_final.iloc[0]['Vsample1':'Vsample4096']\n",
    "Data_final.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clustering part 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Processed.head()\n",
    "\n",
    "points = Data_Processed.loc[:,[\"crest\",\"freqAmpliKurt\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters=2)\n",
    "model.fit(points)\n",
    "labels = model.predict(points)\n",
    "xs = points[:,0]\n",
    "ys = points[:,1]\n",
    "plt.scatter(xs, ys, c=labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "model = KMeans(n_clusters=2)\n",
    "model.fit(points)\n",
    "labels = model.predict(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in Data_Processed.columns[6:]:\n",
    "    for j in Data_Processed.columns[6:]:\n",
    "        if i != j:\n",
    "            print(i,j)\n",
    "            points = Data_Processed.loc[:,[i,j]].values\n",
    "            model = KMeans(n_clusters=2)\n",
    "            model.fit(points)\n",
    "            labels = model.predict(points)\n",
    "            xs = points[:,0]\n",
    "            ys = points[:,1]\n",
    "            fig = plt.figure()\n",
    "            plt.scatter(xs, ys, c=labels)\n",
    "            plt.xlabel(i)\n",
    "            plt.ylabel(j)\n",
    "            plt.show()\n",
    "            fig.savefig('./Cluster/'+i+'-Vs-'+j+'.png',dpi=400)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Load_NoLoad_group = {\"No Defect_No Load\": \"No_Load\",\n",
    "                     \"No Defect_Empty Tray\":\"Load\",\n",
    "                     \"No Defect_with no tray\" : \"No_Load\" }\n",
    "\n",
    "Data_Processed[\"Actual_Cluster\"] = [ Load_NoLoad_group[i] for i in Data_Processed.Defect_Introduced]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Processed.columns\n",
    "\n",
    "Data_rearrange = Data_Processed[['Asset_Id', 'Axis', 'Data_pull_time', 'Defect_Introduced', 'Mac_Id',\n",
    "       'Sensor_Loc','Actual_Cluster', 'crest', 'freqAmpliKurt', 'freqAmpliMax', 'freqAmpliMean',\n",
    "       'freqAmpliVar', 'freqAmpliskw', 'kurt', 'max_1', 'max_2', 'max_3',\n",
    "       'max_4', 'max_5', 'max_6', 'max_7', 'max_8', 'mean', 'mean_1', 'mean_2',\n",
    "       'mean_3', 'mean_4', 'mean_5', 'mean_6', 'mean_7', 'mean_8', 'peak-peak',\n",
    "       'rms', 'skewness', 'var_1', 'var_2', 'var_3', 'var_4', 'var_5', 'var_6',\n",
    "       'var_7', 'var_8', 'variance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_rearrange.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EDTgrouped=Data_rearrange.loc[:,\"Defect_Introduced\":\"variance\"]\n",
    "EDTgrouped=EDTgrouped.drop(columns=['Mac_Id','Sensor_Loc'])\n",
    "EDTgrouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = EDTgrouped.loc[:,\"crest\":]  # independent variables data\n",
    "y = EDTgrouped.Actual_Cluster  # dependednt variable data\n",
    "EDTgrouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.apply(np.mean)\n",
    "# Std Deviation\n",
    "X.apply(np.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean and Std deviation by Gp\n",
    "def printMeanAndSdByGroup(variables, groupvariable):\n",
    "    data_groupby = variables.groupby(groupvariable)\n",
    "    print(\"## Means:\")\n",
    "    display(data_groupby.apply(np.mean))\n",
    "    print(\"\\n## Standard deviations:\")\n",
    "    display(data_groupby.apply(np.std))\n",
    "    print(\"\\n## Sample sizes:\")\n",
    "    display(pd.DataFrame(data_groupby.apply(len)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printMeanAndSdByGroup(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardisedX = scale(X)\n",
    "standardisedX = pd.DataFrame(standardisedX, index=X.index, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardisedX.apply(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardisedX.apply(np.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA().fit(standardisedX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_summary(pca, standardised_data, out=True):\n",
    "    names = [\"PC\"+str(i) for i in range(1, len(pca.explained_variance_ratio_)+1)]\n",
    "    a = list(np.std(pca.transform(standardised_data), axis=0))\n",
    "    b = list(pca.explained_variance_ratio_)\n",
    "    c = [np.sum(pca.explained_variance_ratio_[:i]) for i in range(1, len(pca.explained_variance_ratio_)+1)]\n",
    "    columns = pd.MultiIndex.from_tuples([(\"sdev\", \"Standard deviation\"), (\"varprop\", \"Proportion of Variance\"), (\"cumprop\", \"Cumulative Proportion\")])\n",
    "    summary = pd.DataFrame(zip(a, b, c), index=names, columns=columns)\n",
    "    if out:\n",
    "        print(\"Importance of components:\")\n",
    "        display(summary)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pca_summary(pca, standardisedX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def screeplot(pca, standardised_values):\n",
    "    y = np.std(pca.transform(standardised_values), axis=0)**2\n",
    "    x = np.arange(len(y)) + 1\n",
    "    plt.plot(x, y, \"o-\")\n",
    "    plt.xticks(x, [\"Comp.\"+str(i) for i in x], rotation=60)\n",
    "    plt.ylabel(\"Variance\")\n",
    "    plt.show()\n",
    "\n",
    "screeplot(pca, standardisedX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Kaiserâ€™s criterion: that we should only retain principal components for which the variance is above 1\n",
    "summary.sdev**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_scatter(pca, standardised_values, classifs):\n",
    "    foo = pca.transform(standardised_values)\n",
    "    bar = pd.DataFrame(zip(foo[:, 0], foo[:, 1], classifs), columns=[\"PC1\", \"PC2\", \"Class\"])\n",
    "    sns.lmplot(\"PC1\", \"PC2\", bar, hue=\"Class\", fit_reg=False)\n",
    "\n",
    "pca_scatter(pca, standardisedX, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
