{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "db = mongoConnection['TestLoop_RawData_MP']\n",
    "print(db.DATA_To_MPHERE.count())\n",
    "print(db['Time_Last_Extracted'].count())\n",
    "\n",
    "#db['Time_Last_Extracted'].drop()\n",
    "#db['DATA_To_MPHERE'].drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data till\n",
    "\n",
    "End_timestamp = dt.strptime(\"2020-07-12\", '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from urllib.parse import urlparse\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from gql import Client, gql\n",
    "from gql.transport.requests import RequestsHTTPTransport\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt, timedelta as td\n",
    "from pymongo import MongoClient\n",
    "from GetMacIDList import IQNet_MacId_list # will get us the list of macids connected to iqunet server\n",
    "#from GraphQL_Client import GraphQLClient\n",
    "logging.basicConfig(filename='Raw_to_Mongodb.log',level=logging.DEBUG)\n",
    "logging.info('Importing raw data from Iqnet to MongoDB {}'.format(dt.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphQLClient(object):\n",
    "    CONNECT_TIMEOUT = 15  # [sec]\n",
    "    RETRY_DELAY = 10  # [sec]\n",
    "    MAX_RETRIES = 3  # [-]\n",
    "\n",
    "    class Decorators(object):\n",
    "        @staticmethod\n",
    "        def autoConnectingClient(wrappedMethod):\n",
    "            def wrapper(obj, *args, **kwargs):\n",
    "                for retry in range(GraphQLClient.MAX_RETRIES):\n",
    "                    try:\n",
    "                        return wrappedMethod(obj, *args, **kwargs)\n",
    "                    except Exception:\n",
    "                        pass\n",
    "                    try:\n",
    "                        obj._logger.warning(\n",
    "                                '(Re)connecting to GraphQL service.'\n",
    "                        )\n",
    "                        obj.reconnect()\n",
    "                    except ConnectionRefusedError:\n",
    "                        obj._logger.warn(\n",
    "                            'Connection refused. Retry in 10s.'.format(\n",
    "                                GraphQLClient.RETRY_DELAY\n",
    "                            )\n",
    "                        )\n",
    "                        time.sleep(GraphQLClient.RETRY_DELAY)\n",
    "                else:  # So the exception is exposed.\n",
    "                    obj.reconnect()\n",
    "                    return wrappedMethod(obj, *args, **kwargs)\n",
    "            return wrapper\n",
    "\n",
    "    def __init__(self, serverUrl):\n",
    "        self._logger = logging.getLogger(self.__class__.__name__)\n",
    "        self.connect(\n",
    "            serverUrl.geturl()\n",
    "        )\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.connect(\n",
    "            serverUrl.geturl()\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        self._client = None\n",
    "\n",
    "    def connect(self, url):\n",
    "        host = url.split('//')[1].split('/')[0]\n",
    "        request = requests.get(url,\n",
    "                               headers={\n",
    "                                       'Host': str(host),\n",
    "                                       'Accept': 'text/html',\n",
    "                                       }\n",
    "                               )\n",
    "        request.raise_for_status()\n",
    "        csrf = request.cookies['csrftoken']\n",
    "        self._client = Client(\n",
    "                transport=RequestsHTTPTransport(url=url,\n",
    "                                                cookies={\"csrftoken\": csrf},\n",
    "                                                headers={'x-csrftoken':  csrf}\n",
    "                                                ),\n",
    "                fetch_schema_from_transport=True\n",
    "                )\n",
    "\n",
    "    def disconnect(self):\n",
    "        self._client = None\n",
    "\n",
    "    def reconnect(self):\n",
    "        self.disconnect()\n",
    "        self.connect(\n",
    "            serverUrl.geturl()\n",
    "        )\n",
    "\n",
    "    @Decorators.autoConnectingClient\n",
    "    def execute_query(self, querytext):\n",
    "        query = gql(querytext)\n",
    "        return self._client.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataAcquisition(object):\n",
    "    LOGGER = logging.getLogger('DataAcquisition')\n",
    "\n",
    "    @staticmethod\n",
    "    def get_sensor_data(serverUrl, macId, starttime, endtime, limit, axis,last_extract):\n",
    "        with GraphQLClient(serverUrl) as client:\n",
    "            querytext = '''\n",
    "            { deviceManager { device(macId:\"''' + macId + '''\") {\n",
    "                __typename\n",
    "                ... on GrapheneVibrationCombo {vibrationTimestampHistory(start:\"''' + str(starttime) + '''\", end:\"''' + str(endtime) + '''\", limit:''' + str(limit) + ''', axis:\"''' + axis + '''\")}\n",
    "            }}}\n",
    "            '''\n",
    "            #print('1st one : ' + querytext)\n",
    "            result = client.execute_query(querytext)\n",
    "            #print(result.keys())\n",
    "            times = \\\n",
    "                result['deviceManager']['device']['vibrationTimestampHistory']\n",
    "            dates, values, franges = ([], [], [])\n",
    "            for t in times:\n",
    "                #print(t)\n",
    "                if len(t) == 32:\n",
    "                    Iqnet_time = dt.strptime(t[:-13],'%Y-%m-%dT%H:%M:%S') + td(hours=4) # adding 4 hours to iqnet time coz of timezone\n",
    "                elif len(t) == 25:\n",
    "                    Iqnet_time = dt.strptime(t[:-6],'%Y-%m-%dT%H:%M:%S') + td(hours=4)\n",
    "                else:\n",
    "                    continue\n",
    "                if (Iqnet_time >= last_extract):\n",
    "                    #print(Iqnet_time)\n",
    "                    result = DataAcquisition.get_sensor_measurement(\n",
    "                        client,\n",
    "                        macId,\n",
    "                        t\n",
    "                    )\n",
    "                    dates.append(t)\n",
    "                    deviceData = result['deviceManager']['device']\n",
    "                    values.append(\n",
    "                            deviceData['vibrationArray']['rawSamples']\n",
    "                    )\n",
    "                    franges.append(\n",
    "                            deviceData['vibrationArray']['formatRange']\n",
    "                    )\n",
    "            return (values, dates, franges)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_sensor_measurement(client, macId, isoDate):\n",
    "        querytext = '''\n",
    "        { deviceManager { device(macId:\"''' + macId + '''\") {\n",
    "        __typename\n",
    "        ... on GrapheneVibrationCombo { vibrationArray(isoDate: \"''' + isoDate + '''\") {\n",
    "        numSamples rawSamples sampleRate formatRange axis }}\n",
    "        }}}\n",
    "        '''\n",
    "        #print('2nd one : '+querytext)\n",
    "        return client.execute_query(querytext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    mongoConnection = MongoClient('mongodb://localhost:27017/')\n",
    "    logging.info('Successfully connected to MongoDB')\n",
    "except:\n",
    "    logging.warning('Could not connect to MongoDB Database!!!')\n",
    "# Switch to Existing Database named siemensDubai_iQunet_Processed_Database\n",
    "\n",
    "db = mongoConnection['TestLoop_RawData_MP']\n",
    "Datacollection = db['DATA_To_MPHERE']\n",
    "DF_Sensor_Loc = db['Time_Last_Extracted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save timestamp of the last value extracted from iqnet for a specific sensor\n",
    "def getDateTimeforMacId(macId):\n",
    "    global localDatabaseConnection,installationDate\n",
    "    # Creat Collection, its similar to tables in RDBMS\n",
    "    db = mongoConnection['TestLoop_RawData_MP']\n",
    "    DF_Sensor_Loc = db['Time_Last_Extracted']\n",
    "    if DF_Sensor_Loc.count_documents({'macId':macId})>0:    \n",
    "        myPrecious = DF_Sensor_Loc.find_one({'macId':macId})\n",
    "    else:\n",
    "        myPrecious={\n",
    "                \"macId\": macId,\n",
    "                \"MStartDate\": dt.strptime(\"2020-07-10 00:00:00\", '%Y-%m-%d %H:%M:%S')\n",
    "                }\n",
    "        DF_Sensor_Loc.insert_one(myPrecious)\n",
    "#    print('\\n',dataType,myPrecious.get('MStartDate'))\n",
    "    return myPrecious.get('MStartDate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateDateTimeforMacId(macId,Next_startDate):\n",
    "    global localDatabaseConnection\n",
    "    #localCollection = localDatabaseConnection.iQunet_Macid_DatesToStart\n",
    "    db = mongoConnection['TestLoop_RawData_MP']\n",
    "    DF_Sensor_Loc = db['Time_Last_Extracted']\n",
    "    dateToUpdate=Next_startDate+td(seconds=1)\n",
    "    myquery = { \"macId\": macId }\n",
    "    newvalues = { \"$set\": { \"MStartDate\": dateToUpdate } }\n",
    "    DF_Sensor_Loc.update_one(myquery, newvalues)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "db['New_raw_data'].remove({\"Sensor_Loc\":\"MER-ED3\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testiing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def check_entry_exits(row):\n",
    "    DF_Sensor_Loc = db['Mac_Fault_list']\n",
    "    try:\n",
    "        if(DF_Sensor_Loc.find({ \"Entry Date\":     row[\"Entry Date\"],                         \\\n",
    "                           \"Asset-Id\":row[\"Asset-Id\"], \\\n",
    "                           \"Sensor Location\":row[\"Sensor Location\"],\\\n",
    "                           \"Macid\":row[\"Macid\"],\n",
    "                         \"Start Time\":  row[\"Start Time\"], \\\n",
    "                         \"End Time\": row[\"End Time\"]}).count() == 0):\n",
    "            DF_Sensor_Loc.insert_one(row.to_dict())\n",
    "            return True # data does not exits hence insert and data will be loaded with no duplicates\n",
    "        else:\n",
    "            #print(\"Found entry\")\n",
    "            return False # As the data already exits raw data will not be loaded\n",
    "    except ValueError:\n",
    "            return False # skip entry when there is any data missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ip address of the server\n",
    "serverIP = \"192.168.x.x\"\n",
    "serverUrl = urlparse('http://{:s}:8000/graphql'.format(serverIP))\n",
    "\n",
    "#macIds = ['4c:92:10:8c']\n",
    "macIds = IQNet_MacId_list()  # function to get the list of macids configured in iqnet server\n",
    "\n",
    "limit = 200  # limit limits the number of returned measurements.  sample time per hour into hours 6 * 24\n",
    "axis_list = ['X','Y','Z'] # axis allows to select data from only 1 or multiple axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list2 = ['Vsample' + str(x) for x in range(1,4097)]\n",
    "col_list1 =['Data_pull_time','Mac_Id','Axis']\n",
    "columns = col_list1+ col_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 4099)\n",
      "No Data Avaiable or respective entries already imported\n",
      "(198, 4099)\n",
      "Data Import Successfully Completed\n",
      "(198, 4099)\n",
      "(207, 4099)\n",
      "Data Import Successfully Completed\n",
      "(207, 4099)\n",
      "(192, 4099)\n",
      "Data Import Successfully Completed\n",
      "(192, 4099)\n",
      "(192, 4099)\n",
      "Data Import Successfully Completed\n",
      "(192, 4099)\n",
      "(0, 4099)\n",
      "No Data Avaiable or respective entries already imported\n",
      "(216, 4099)\n",
      "Data Import Successfully Completed\n",
      "(216, 4099)\n",
      "(0, 4099)\n",
      "No Data Avaiable or respective entries already imported\n",
      "(180, 4099)\n",
      "Data Import Successfully Completed\n",
      "(180, 4099)\n",
      "(156, 4099)\n",
      "Data Import Successfully Completed\n",
      "(156, 4099)\n",
      "(0, 4099)\n",
      "No Data Avaiable or respective entries already imported\n",
      "(177, 4099)\n",
      "Data Import Successfully Completed\n",
      "(177, 4099)\n",
      "(234, 4099)\n",
      "Data Import Successfully Completed\n",
      "(234, 4099)\n",
      "(0, 4099)\n",
      "No Data Avaiable or respective entries already imported\n",
      "(171, 4099)\n",
      "Data Import Successfully Completed\n",
      "(171, 4099)\n",
      "(0, 4099)\n",
      "No Data Avaiable or respective entries already imported\n",
      "(177, 4099)\n",
      "Data Import Successfully Completed\n",
      "(177, 4099)\n",
      "(0, 4099)\n",
      "No Data Avaiable or respective entries already imported\n"
     ]
    }
   ],
   "source": [
    "# new code to extract raw data and save the time of last value extracted and to start from there next time\n",
    "for Id in list(macIds):\n",
    "    data = []\n",
    "    for axis in axis_list:\n",
    "        last_extract_date = getDateTimeforMacId(Id)\n",
    "        Start_date = last_extract_date.date()\n",
    "        End_Date = End_timestamp.date() # testing end date\n",
    "        logging.info('{} {} : Data extraction between {} and {}'.format(Id,axis,last_extract_date,End_Date))\n",
    "        try:\n",
    "            (values, dates, franges) = DataAcquisition.get_sensor_data(serverUrl=serverUrl,macId=Id,starttime=Start_date,endtime=End_Date,limit=limit,axis=axis,last_extract=last_extract_date)\n",
    "        except KeyError:\n",
    "            logging.warning('No data available for Macid : {} axis : {}'.format(Id,axis))\n",
    "            continue\n",
    "        line = []\n",
    "        for i in range(len(franges)):\n",
    "            values[i] = [d/512.0*franges[i] for d in values[i]]\n",
    "            if len(dates[i]) == 32:\n",
    "                Iq_time = dt.strptime(dates[i][:-13],'%Y-%m-%dT%H:%M:%S') + td(hours=4) # adding 4 hours to iqnet time coz of timezone\n",
    "            elif len(dates[i]) == 25:\n",
    "                Iq_time = dt.strptime(dates[i][:-6],'%Y-%m-%dT%H:%M:%S') + td(hours=4)\n",
    "            else:\n",
    "                continue\n",
    "            line.append(Iq_time)\n",
    "            line.append(Id)\n",
    "            line.append(axis)\n",
    "            line.extend(values[i])\n",
    "            data.append(line)  \n",
    "            line=[]     \n",
    "    if len(data) > 0:\n",
    "        if len(data[0]) != 4099:\n",
    "            continue\n",
    "    df = pd.DataFrame(data,columns=columns)\n",
    "    df.reset_index(inplace=True,drop=True)\n",
    "    max_date = df.Data_pull_time.max()\n",
    "    data_dict = df.to_dict(\"records\")\n",
    "    if len(data_dict) > 0 and df.shape[1] == 4099:\n",
    "        db['DATA_To_MPHERE'].insert_many(data_dict)\n",
    "        updateDateTimeforMacId(Id,max_date)\n",
    "        logging.info('For Mac Id {} {} rows imported, imported till {}'.format(Id,df.shape[0],max_date))\n",
    "    else:\n",
    "        updateDateTimeforMacId(Id,End_timestamp)\n",
    "        logging.info('No Data Available for Mac Id {}'.format(Id))\n",
    "    #df.to_excel(Id.replace(\":\",\"\")+\"_TEST_LOOP_RAW_DATA\"+'.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get the date stored for each macid\n",
    "macIds = IQNet_MacId_list()\n",
    "for Id in list(macIds):\n",
    "    last_extract_date = getDateTimeforMacId(Id)\n",
    "    print(Id +': '+ str(last_extract_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
