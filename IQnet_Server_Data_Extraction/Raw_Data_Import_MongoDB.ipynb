{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'GetMacIDList'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-412c90706867>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimedelta\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpymongo\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMongoClient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mGetMacIDList\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mIQNet_MacId_list\u001b[0m \u001b[1;31m# will get us the list of macids connected to iqunet server\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m#from GraphQL_Client import GraphQLClient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'GetMacIDList'"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from urllib.parse import urlparse\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from gql import Client, gql\n",
    "from gql.transport.requests import RequestsHTTPTransport\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt, timedelta as td\n",
    "from pymongo import MongoClient\n",
    "from GetMacIDList import IQNet_MacId_list # will get us the list of macids connected to iqunet server\n",
    "import os\n",
    "#from GraphQL_Client import GraphQLClient\n",
    "#from GraphQL_DataExtract import DataAcquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphQLClient(object):\n",
    "    CONNECT_TIMEOUT = 15  # [sec]\n",
    "    RETRY_DELAY = 10  # [sec]\n",
    "    MAX_RETRIES = 3  # [-]\n",
    "\n",
    "    class Decorators(object):\n",
    "        @staticmethod\n",
    "        def autoConnectingClient(wrappedMethod):\n",
    "            def wrapper(obj, *args, **kwargs):\n",
    "                for retry in range(GraphQLClient.MAX_RETRIES):\n",
    "                    try:\n",
    "                        return wrappedMethod(obj, *args, **kwargs)\n",
    "                    except Exception:\n",
    "                        pass\n",
    "                    try:\n",
    "                        obj._logger.warning(\n",
    "                                '(Re)connecting to GraphQL service.'\n",
    "                        )\n",
    "                        obj.reconnect()\n",
    "                    except ConnectionRefusedError:\n",
    "                        obj._logger.warn(\n",
    "                            'Connection refused. Retry in 10s.'.format(\n",
    "                                GraphQLClient.RETRY_DELAY\n",
    "                            )\n",
    "                        )\n",
    "                        time.sleep(GraphQLClient.RETRY_DELAY)\n",
    "                else:  # So the exception is exposed.\n",
    "                    obj.reconnect()\n",
    "                    return wrappedMethod(obj, *args, **kwargs)\n",
    "            return wrapper\n",
    "\n",
    "    def __init__(self, serverUrl):\n",
    "        self._logger = logging.getLogger(self.__class__.__name__)\n",
    "        self.connect(\n",
    "            serverUrl.geturl()\n",
    "        )\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.connect(\n",
    "            serverUrl.geturl()\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        self._client = None\n",
    "\n",
    "    def connect(self, url):\n",
    "        host = url.split('//')[1].split('/')[0]\n",
    "        request = requests.get(url,\n",
    "                               headers={\n",
    "                                       'Host': str(host),\n",
    "                                       'Accept': 'text/html',\n",
    "                                       }\n",
    "                               )\n",
    "        request.raise_for_status()\n",
    "        csrf = request.cookies['csrftoken']\n",
    "        self._client = Client(\n",
    "                transport=RequestsHTTPTransport(url=url,\n",
    "                                                cookies={\"csrftoken\": csrf},\n",
    "                                                headers={'x-csrftoken':  csrf}\n",
    "                                                ),\n",
    "                fetch_schema_from_transport=True\n",
    "                )\n",
    "\n",
    "    def disconnect(self):\n",
    "        self._client = None\n",
    "\n",
    "    def reconnect(self):\n",
    "        self.disconnect()\n",
    "        self.connect(\n",
    "            serverUrl.geturl()\n",
    "        )\n",
    "\n",
    "    @Decorators.autoConnectingClient\n",
    "    def execute_query(self, querytext):\n",
    "        query = gql(querytext)\n",
    "        return self._client.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataAcquisition(object):\n",
    "    LOGGER = logging.getLogger('DataAcquisition')\n",
    "\n",
    "    @staticmethod\n",
    "    def get_sensor_data(serverUrl, macId, starttime, endtime, limit, axis,Start_Time,End_Time,):\n",
    "        with GraphQLClient(serverUrl) as client:\n",
    "            querytext = '''\n",
    "            { deviceManager { device(macId:\"''' + macId + '''\") {\n",
    "                __typename\n",
    "                ... on GrapheneVibrationCombo {vibrationTimestampHistory(start:\"''' + str(starttime) + '''\", end:\"''' + str(endtime) + '''\", limit:''' + str(limit) + ''', axis:\"''' + axis + '''\")}\n",
    "            }}}\n",
    "            '''\n",
    "            #print('1st one : ' + querytext)\n",
    "            result = client.execute_query(querytext)\n",
    "            #print(result.keys())\n",
    "            times = \\\n",
    "                result['deviceManager']['device']['vibrationTimestampHistory']\n",
    "            dates, values, franges = ([], [], [])\n",
    "            for t in times:\n",
    "                #print(t)\n",
    "                if len(t) == 32:\n",
    "                    Iqnet_time = dt.strptime(t[:-13],'%Y-%m-%dT%H:%M:%S') + td(hours=4) # adding 4 hours to iqnet time coz of timezone\n",
    "                elif len(t) == 25:\n",
    "                    Iqnet_time = dt.strptime(t[:-6],'%Y-%m-%dT%H:%M:%S') + td(hours=4)\n",
    "                else:\n",
    "                    contine\n",
    "                if (Iqnet_time >= Start_Time) and (Iqnet_time <= End_Time):\n",
    "                    #print(Iqnet_time)\n",
    "                    result = DataAcquisition.get_sensor_measurement(\n",
    "                        client,\n",
    "                        macId,\n",
    "                        t\n",
    "                    )\n",
    "                    dates.append(t)\n",
    "                    deviceData = result['deviceManager']['device']\n",
    "                    values.append(\n",
    "                            deviceData['vibrationArray']['rawSamples']\n",
    "                    )\n",
    "                    franges.append(\n",
    "                            deviceData['vibrationArray']['formatRange']\n",
    "                    )\n",
    "            return (values, dates, franges)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_sensor_measurement(client, macId, isoDate):\n",
    "        querytext = '''\n",
    "        { deviceManager { device(macId:\"''' + macId + '''\") {\n",
    "        __typename\n",
    "        ... on GrapheneVibrationCombo { vibrationArray(isoDate: \"''' + isoDate + '''\") {\n",
    "        numSamples rawSamples sampleRate formatRange axis }}\n",
    "        }}}\n",
    "        '''\n",
    "        #print('2nd one : '+querytext)\n",
    "        return client.execute_query(querytext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    mongoConnection = MongoClient('mongodb://localhost:27017/')\n",
    "except:\n",
    "    print(\"Could not connect to MongoDB Database!!!\")\n",
    "    logging.warning('Could not connect to MongoDB Database!!!')\n",
    "# Switch to Existing Database named siemensDubai_iQunet_Processed_Database\n",
    "\n",
    "db = mongoConnection['TestLoop_NewRaw_Data']\n",
    "Datacollection = db['New_raw_data']\n",
    "DF_Sensor_Loc = db['Mac_Fault_list']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "db['Mac_Fault_list'].drop()\n",
    "db['New_raw_data'].drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: count is deprecated. Use estimated_document_count or count_documents instead. Please note that $where must be replaced by $expr, $near must be replaced by $geoWithin with $center, and $nearSphere must be replaced by $geoWithin with $centerSphere\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: count is deprecated. Use estimated_document_count or count_documents instead. Please note that $where must be replaced by $expr, $near must be replaced by $geoWithin with $center, and $nearSphere must be replaced by $geoWithin with $centerSphere\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print(db.Mac_Fault_list.count())\n",
    "print(db['New_raw_data'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_entry_exits(row):\n",
    "    DF_Sensor_Loc = db['Mac_Fault_list']\n",
    "    try:\n",
    "        if(DF_Sensor_Loc.find({ \"Entry Date\":     row[\"Entry Date\"],                         \\\n",
    "                           \"Asset-Id\":row[\"Asset-Id\"], \\\n",
    "                           \"Sensor Location\":row[\"Sensor Location\"],\\\n",
    "                           \"Macid\":row[\"Macid\"],\n",
    "                         \"Start Time\":  row[\"Start Time\"], \\\n",
    "                         \"End Time\": row[\"End Time\"]}).count() == 0):\n",
    "            DF_Sensor_Loc.insert_one(row.to_dict())\n",
    "            return True # data does not exits hence insert and data will be loaded with no duplicates\n",
    "        else:\n",
    "            #print(\"Found entry\")\n",
    "            return False # As the data already exits raw data will not be loaded\n",
    "    except ValueError:\n",
    "            return False # skip entry when there is any data missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ip address of the server\n",
    "serverIP = \"192.168.x.x\"\n",
    "serverUrl = urlparse('http://{:s}:8000/graphql'.format(serverIP))\n",
    "\n",
    "#macIds = ['4c:92:10:8c']\n",
    "macIds = IQNet_MacId_list()  # function to get the list of macids configured in iqnet server\n",
    "\n",
    "limit = 200  # limit limits the number of returned measurements.  sample time per hour into hours 6 * 24\n",
    "axis_list = ['X','Y','Z'] # axis allows to select data from only 1 or multiple axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sesnor_loc = pd.read_excel('Induced Failures in the test Loop.xlsx',sheet_name='Log of induced defects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list2 = ['Vsample' + str(x) for x in range(1,4097)]\n",
    "col_list1 =['Data_pull_time','Mac_Id','Axis','Defect_Introduced','Asset_Id','Sensor_Loc']\n",
    "columns = col_list1+ col_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 4102)\n",
      "No Data Avaiable or All datas respective to Excel entries are already imported\n",
      "(0, 4102)\n",
      "No Data Avaiable or All datas respective to Excel entries are already imported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: count is deprecated. Use Collection.count_documents instead.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(604, 4102)\n",
      "Data Import Successfully Completed\n",
      "(504, 4102)\n",
      "Data Import Successfully Completed\n",
      "(555, 4102)\n",
      "Data Import Successfully Completed\n",
      "(0, 4102)\n",
      "No Data Avaiable or All datas respective to Excel entries are already imported\n",
      "(0, 4102)\n",
      "No Data Avaiable or All datas respective to Excel entries are already imported\n",
      "(0, 4102)\n",
      "No Data Avaiable or All datas respective to Excel entries are already imported\n",
      "(0, 4102)\n",
      "No Data Avaiable or All datas respective to Excel entries are already imported\n",
      "(635, 4102)\n",
      "Data Import Successfully Completed\n",
      "(518, 4102)\n",
      "Data Import Successfully Completed\n",
      "(517, 4102)\n",
      "Data Import Successfully Completed\n",
      "(0, 4102)\n",
      "No Data Avaiable or All datas respective to Excel entries are already imported\n",
      "(0, 4102)\n",
      "No Data Avaiable or All datas respective to Excel entries are already imported\n",
      "(0, 4102)\n",
      "No Data Avaiable or All datas respective to Excel entries are already imported\n",
      "(0, 4102)\n",
      "No Data Avaiable or All datas respective to Excel entries are already imported\n",
      "(600, 4102)\n",
      "Data Import Successfully Completed\n",
      "(543, 4102)\n",
      "Data Import Successfully Completed\n",
      "(617, 4102)\n",
      "Data Import Successfully Completed\n",
      "(537, 4102)\n",
      "Data Import Successfully Completed\n"
     ]
    }
   ],
   "source": [
    "Dest = dt.now().strftime('%d-%b-%Y')\n",
    "if not os.path.exits(Dest):\n",
    "    os.mkdir(Dest)\n",
    "    \n",
    "\n",
    "for Id in list(macIds):\n",
    "    #print(Id)\n",
    "    data = []\n",
    "    df_macid = df_sesnor_loc[df_sesnor_loc['Macid'] == Id] # filter data for a particular id\n",
    "    for index, row in df_macid.iterrows():\n",
    "        #print(check_entry_exits(row))\n",
    "        while (check_entry_exits(row)):\n",
    "            for axis in axis_list:\n",
    "                Start_Time,End_Time = row['Start Time'],row['End Time']\n",
    "                Start_date = Start_Time.date()\n",
    "                End_Date =  Start_date+ td(days=1)\n",
    "        \n",
    "                (values, dates, franges) = DataAcquisition.get_sensor_data(serverUrl=serverUrl,macId=Id,starttime=Start_date,endtime=End_Date,limit=limit,axis=axis,Start_Time=Start_Time,End_Time=End_Time)\n",
    "                line = []\n",
    "                for i in range(len(franges)):\n",
    "                    values[i] = [d/512.0*franges[i] for d in values[i]]\n",
    "                    if len(dates[i]) == 32:\n",
    "                        Iq_time = dt.strptime(dates[i][:-13],'%Y-%m-%dT%H:%M:%S') + td(hours=4) # adding 4 hours to iqnet time coz of timezone\n",
    "                    elif len(dates[i]) == 25:\n",
    "                        Iq_time = dt.strptime(dates[i][:-6],'%Y-%m-%dT%H:%M:%S') + td(hours=4)\n",
    "                    else:\n",
    "                        contine\n",
    "                    line.append(Iq_time)\n",
    "                    line.append(Id)\n",
    "                    line.append(axis)\n",
    "                    line.append(row['Defects Introduced'])\n",
    "                    line.append(row['Asset-Id'])\n",
    "                    line.append(row['Sensor Location'])\n",
    "                    for val in range(len(values[i])):\n",
    "                        #print(val)\n",
    "                        line.append(values[i][val])\n",
    "                        #line+='\\n'\n",
    "                    data.append(line)\n",
    "                    line=[]\n",
    "    df = pd.DataFrame(data,columns=columns)\n",
    "    #print(df.shape)\n",
    "    df.reset_index(inplace=True)\n",
    "    data_dict = df.to_dict(\"records\")\n",
    "    if len(data_dict) > 0:\n",
    "        db['New_raw_data'].insert_many(data_dict)\n",
    "        print('Data Import Successfully Completed')\n",
    "    else:\n",
    "        print('No Data Avaiable or All datas respective to Excel entries are already imported')\n",
    "    df.to_excel('./'+Dest+'/'+Id.replace(\":\",\"\")+\"_TEST_LOOP_RAW_DATA\"+'.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'19-Aug-2020'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.now().strftime('%d-%b-%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(dt.now().strftime('%d-%b-%Y')):\n",
    "    os.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
